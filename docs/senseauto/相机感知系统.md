## 相机感知系统

### 回放实现相关

设置 system_mode = rec_replay

Python脚本

- srcipt/replayer_helper.py - 传感器rec数据和视频回放的配置生成
  - ${replayer_helper} -d ${video_dir} -o ${input_config} ${without_videos}
  - 当rec_replay时 without_videos = false
- 将传感器及视频的信息写入json文件( 默认为: ./input.json )
  
- script/node_config_generator.py
  - ${node_config_generator} -m ${mode} -d ${video_dir} -c ${map} -g ${system} ${custom_config}  ${is_online} ${use_local_config} --custom_arguments "input_config:=${input_config}" ${remain_unpassed_args}
  - 会写入到./system/launcher/.cache/{time}.conf文件，同时将对应的latest.conf软链接到这个config文件
  - 配置rec_replayer 的ros_param (input.json的路径)
  - 配置结果如下

```
- rec_replayer:
    args:
      pause: 'true'
      input_config: /home/sensetime/data/senseauto_data/0104_amba/2021_01_04_18_03_27//input.json
```

#### ros_rec_replayer & senseAD::sensor::Replayer

分为读取和发送两部分，使用生产者/消费者机制

- dispatcher消费过后，file_reader会自动读取下一帧

##### file_reader

- 读取input_config.json获取到传感器的文件信息
- 根据文件信息创建file_handlers_
  - NORMAL类型是普通的传感器 - 对应 RecFileHandler
  - VIDEO类型是视频 - 对应 PortVideoHandler
    - 使用opencv的VideoCapture读入到指定地址，即TopicRawData，包括时间戳和视频两部分数据
  - 每个file_handler对应一个DataBuffer\<TopicRawData\>::NodePtr
  - 读取数据： handler->GetNextNode : read_data
- WaitReturnProducerPtr

##### dispatcher

- buffer和attribute是从file_reader中获取
  - 基础信息有type和topic
  - Camera的attribute包括两部分 size 和 index，topic为配置文件input.json中的"port"字段
  - rec文件的attr包括length
- 为每一个attr(也就是每一个传感器)，创建一个sender，并绑定topic信息
  - shm共享内存底层在SenderWrapper中实现
- sendCallBack
  - ros_rec_replayer -> replayer -> dispatcher
  - 通过这个回调函数来设置sim_time
- WaitConsumerPtr

#### RosTopic

| Topic                               | Topic ID                              | 描述             |
| ----------------------------------- | ------------------------------------- | ---------------- |
|                                     |                                       |                  |
| 仅ros_camera                        | PERCEPTION_CAMERA_IMAGE               |                  |
| **camera_perception Node**          |                                       |                  |
| /camera_object/objects              |                                       |                  |
| /camera_object/sensor_frames        |                                       |                  |
|                                     |                                       |                  |
| **perception_Aggregator Node**      |                                       |                  |
| /center_camera_object/sensor_frames | PERCEPTION_CENTER_CAMERA_SENSOR_FRAME | SensorFrameArray |
| /camera_object/sensor_frames        | PERCEPTION_CAMERA_OBJECT_SENSOR_FRAME | SensorFrameArray |
|                                     |                                       |                  |

### 相机感知相关

回放时，使用的是CameraIPC，每辆车的回放视频的port已经提前设置好，大部分车都是"AB"，也就是camera_0

相关实现见./modules/common/pre_process/sensors/camera/camera_ipc.cpp/hpp

|       函数        |         描述          |
| :---------------: | :-------------------: |
| processDetectTask | Main Process Pipeline |
|                   |                       |
|                   |                       |

ProcessDetectTask

1. 首先判断不是rosCamera

2. 设置时间戳，IPCCamera应该是从文件读取，所以没有被赋值（camera_ipc.cpp/SetCaptureTime）

3. 获取图片，同时获取时间戳

   1. 读取数据到cpu_images (文件数据指针data_)

      - 接收Camera数据的相关模块由VirtualCameraReceiverIPC实现**，与Rec_Replayer的接口关键在于port字符串**
        - fd_ = shm_open(**port_name_.c_str()**, O_RDWR | O_CREAT, 0666);
      - #include <sys/mman.h> #include <sys/stat.h>
      - 这里使用了shm技术（共享内存shared Memory）
      - fstat 获取文件状态 （init_mem）
      - 初始化时打开共享文件 int shm_open(const char \*name, int oflag, mode_t mode);
      - 使用mmap的方式进行读取 void* mmap(void* start,size_t length,int prot,int flags,int fd,off_t offset); 

   2. 回放时使用data_中记录的时间戳 ,记录到capture_time

4. 把cpu_image导入到GPU , cudaMemcpy -- HostToDevice

5. wait_sync_video(不执行)，还不清楚什么用

6. cudaMemcpy 到 raw_image_gpu_buffer_ (目测是GPU到GPU)

   - cudaMemcpy  ( void* **dst** ,const void ***src**, size_t  count, enum cudaMemcpyKind kind)   
     -  count 是 bytes 个数，不是数据类型个数！！！！

7. 执行processDetectTask

   1. raw_image_gpu_buffer_ 拷贝到 raw_image_gpu_cache_
   2. 去畸变 undisortion raw_image_gpu_cache_ -> undistorted_image_gpu_cache_
   3. publish 去畸变后的Image（默认false跳过）
   4. 如果使用外部标定参数，则读取外部标定（默认false跳过）
   5. Detect Objects
      - camera_pipeline_->AddGpuImageToFrame : 
        - undistorted_image_gpu_cache ->  camera_pipeline.frame
   6. pipeline.process
      - prototxt ：po_pipeline_config_file
        - ImagePreprocessOP_1
        - RPNGeneralPredictorOP1
        - RPNStagePostProcessOP1
        - DETGeneralPredictorOP1
        - DETStagePostProcessOP1
        - DepthSizePostProcessOP1
        - BboxLkfMotOP_ / VEH / PED / BIKE / 
        - CalibrationManagerOP_1 : depth_smooth_1/2/3
        - depth_estiamtion_1
   7. pipeline.getObjectResults
   8. publish SensorFrames

